{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10562b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8863042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_1_PATH = \"meta-llama/Llama-2-7b-chat-hf\" \n",
    "MODEL_2_PATH = \"meta-llama/Llama-2-7b-hf\"       \n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911279d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.58s/it]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:49<00:00, 24.82s/it]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# %%\n",
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_1_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model_1 = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_1_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model_2 = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_2_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"Models loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model_1.to(DEVICE)\n",
    "model_2 = model_2.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_weights(model, move_to_cpu=False,layer_range=None):\n",
    "    weights = {}\n",
    "    \n",
    "    # Embedding weights\n",
    "    embed_weight = model.model.embed_tokens.weight\n",
    "    weights['embed_tokens'] = embed_weight.detach().cpu() if move_to_cpu else embed_weight.detach()\n",
    "    \n",
    "    # Layer-specific weights\n",
    "    if layer_range is None:\n",
    "        layer_range = range(len(model.model.layers))\n",
    "    \n",
    "    for i in layer_range:\n",
    "        if i >= len(model.model.layers):\n",
    "            continue\n",
    "            \n",
    "        layer = model.model.layers[i]\n",
    "        layer_prefix = f\"layer_{i}\"\n",
    "        \n",
    "        # Self-attention weights\n",
    "        weights[f\"{layer_prefix}_q_proj\"] = layer.self_attn.q_proj.weight.detach().cpu() if move_to_cpu else layer.self_attn.q_proj.weight.detach()\n",
    "        weights[f\"{layer_prefix}_k_proj\"] = layer.self_attn.k_proj.weight.detach().cpu() if move_to_cpu else layer.self_attn.k_proj.weight.detach()\n",
    "        weights[f\"{layer_prefix}_v_proj\"] = layer.self_attn.v_proj.weight.detach().cpu() if move_to_cpu else layer.self_attn.v_proj.weight.detach()\n",
    "        weights[f\"{layer_prefix}_o_proj\"] = layer.self_attn.o_proj.weight.detach().cpu() if move_to_cpu else layer.self_attn.o_proj.weight.detach()\n",
    "        \n",
    "        # MLP weights\n",
    "        weights[f\"{layer_prefix}_gate_proj\"] = layer.mlp.gate_proj.weight.detach().cpu() if move_to_cpu else layer.mlp.gate_proj.weight.detach()\n",
    "        weights[f\"{layer_prefix}_up_proj\"] = layer.mlp.up_proj.weight.detach().cpu() if move_to_cpu else layer.mlp.up_proj.weight.detach()\n",
    "        weights[f\"{layer_prefix}_down_proj\"] = layer.mlp.down_proj.weight.detach().cpu() if move_to_cpu else layer.mlp.down_proj.weight.detach()\n",
    "        \n",
    "        # Layer norm weights\n",
    "        weights[f\"{layer_prefix}_input_layernorm\"] = layer.input_layernorm.weight.detach().cpu() if move_to_cpu else layer.input_layernorm.weight.detach()\n",
    "        weights[f\"{layer_prefix}_post_attention_layernorm\"] = layer.post_attention_layernorm.weight.detach().cpu() if move_to_cpu else layer.post_attention_layernorm.weight.detach()\n",
    "    \n",
    "    # Final layer norm and LM head\n",
    "    weights['final_norm'] = model.model.norm.weight.detach().cpu() if move_to_cpu else model.model.norm.weight.detach()\n",
    "    weights['lm_head'] = model.lm_head.weight.detach().cpu() if move_to_cpu else model.lm_head.weight.detach()\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def calculate_weight_differences(weights_1, weights_2):\n",
    "    differences = {}\n",
    "    \n",
    "    common_keys = set(weights_1.keys()) & set(weights_2.keys())\n",
    "    print(f\"Comparing {len(common_keys)} weight matrices...\")\n",
    "    \n",
    "    for i, key in enumerate(common_keys):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing {i+1}/{len(common_keys)}: {key}\")\n",
    "            \n",
    "        w1 = weights_1[key]\n",
    "        w2 = weights_2[key]\n",
    "        \n",
    "        if w1.shape != w2.shape:\n",
    "            print(f\"Warning: Shape mismatch for {key}: {w1.shape} vs {w2.shape}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate difference matrix\n",
    "        diff_matrix = w1 - w2\n",
    "        \n",
    "        # Calculate various norms and statistics\n",
    "        frobenius_norm = torch.norm(diff_matrix, p='fro').item()\n",
    "        frobenius_norm_relative = frobenius_norm / (torch.norm(w1, p='fro').item() + 1e-10)\n",
    "        \n",
    "        spectral_norm = torch.norm(diff_matrix, p=2).item()\n",
    "        spectral_norm_relative = spectral_norm / (torch.norm(w1, p=2).item() + 1e-10)\n",
    "        \n",
    "        # Element-wise statistics\n",
    "        abs_diff = torch.abs(diff_matrix)\n",
    "        mean_abs_diff = torch.mean(abs_diff).item()\n",
    "        max_abs_diff = torch.max(abs_diff).item()\n",
    "        std_diff = torch.std(diff_matrix).item()\n",
    "        \n",
    "        # Percentage of significantly different weights (threshold = 1e-6)\n",
    "        significant_diff_ratio = (abs_diff > 1e-6).float().mean().item()\n",
    "        \n",
    "        # Cosine similarity\n",
    "        w1_flat = w1.flatten()\n",
    "        w2_flat = w2.flatten()\n",
    "        cosine_sim = F.cosine_similarity(w1_flat.unsqueeze(0), w2_flat.unsqueeze(0)).item()\n",
    "        \n",
    "        differences[key] = {\n",
    "            'frobenius_norm': frobenius_norm,\n",
    "            'frobenius_norm_relative': frobenius_norm_relative,\n",
    "            'spectral_norm': spectral_norm,\n",
    "            'spectral_norm_relative': spectral_norm_relative,\n",
    "            'mean_abs_difference': mean_abs_diff,\n",
    "            'max_abs_difference': max_abs_diff,\n",
    "            'std_difference': std_diff,\n",
    "            'significant_diff_ratio': significant_diff_ratio,\n",
    "            'cosine_similarity': cosine_sim,\n",
    "            'weight_shape': w1.shape,\n",
    "            'total_parameters': w1.numel()\n",
    "        }\n",
    "    \n",
    "    return differences\n",
    "\n",
    "def analyze_weight_patterns(weight_differences):\n",
    "    analysis = {\n",
    "        'by_component_type': defaultdict(list),\n",
    "        'by_layer_depth': defaultdict(list),\n",
    "        'summary_stats': {}\n",
    "    }\n",
    "    \n",
    "    # Group by component type\n",
    "    for layer_name, diff_data in weight_differences.items():\n",
    "        if any(x in layer_name for x in ['q_proj', 'k_proj', 'v_proj', 'o_proj']):\n",
    "            component_type = 'attention'\n",
    "        elif any(x in layer_name for x in ['gate_proj', 'up_proj', 'down_proj']):\n",
    "            component_type = 'mlp'\n",
    "        elif 'layernorm' in layer_name or 'norm' in layer_name:\n",
    "            component_type = 'normalization'\n",
    "        elif 'embed' in layer_name:\n",
    "            component_type = 'embedding'\n",
    "        elif 'lm_head' in layer_name:\n",
    "            component_type = 'output'\n",
    "        else:\n",
    "            component_type = 'other'\n",
    "        \n",
    "        analysis['by_component_type'][component_type].append({\n",
    "            'layer_name': layer_name,\n",
    "            'frobenius_norm': diff_data['frobenius_norm'],\n",
    "            'frobenius_norm_relative': diff_data['frobenius_norm_relative'],\n",
    "            'significant_diff_ratio': diff_data['significant_diff_ratio'],\n",
    "            'cosine_similarity': diff_data['cosine_similarity']\n",
    "        })\n",
    "    \n",
    "    # Group by layer depth\n",
    "    for layer_name, diff_data in weight_differences.items():\n",
    "        if 'layer_' in layer_name:\n",
    "            try:\n",
    "                layer_num = int(layer_name.split('_')[1])\n",
    "                analysis['by_layer_depth'][layer_num].append({\n",
    "                    'layer_name': layer_name,\n",
    "                    'frobenius_norm': diff_data['frobenius_norm'],\n",
    "                    'frobenius_norm_relative': diff_data['frobenius_norm_relative'],\n",
    "                    'cosine_similarity': diff_data['cosine_similarity']\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    all_frobenius = [data['frobenius_norm'] for data in weight_differences.values()]\n",
    "    all_frobenius_rel = [data['frobenius_norm_relative'] for data in weight_differences.values()]\n",
    "    all_significant_ratios = [data['significant_diff_ratio'] for data in weight_differences.values()]\n",
    "    all_cosine_sims = [data['cosine_similarity'] for data in weight_differences.values()]\n",
    "    \n",
    "    analysis['summary_stats'] = {\n",
    "        'total_layers_compared': len(weight_differences),\n",
    "        'mean_frobenius_norm': np.mean(all_frobenius),\n",
    "        'std_frobenius_norm': np.std(all_frobenius),\n",
    "        'max_frobenius_norm': np.max(all_frobenius),\n",
    "        'min_frobenius_norm': np.min(all_frobenius),\n",
    "        'mean_frobenius_norm_relative': np.mean(all_frobenius_rel),\n",
    "        'mean_significant_diff_ratio': np.mean(all_significant_ratios),\n",
    "        'mean_cosine_similarity': np.mean(all_cosine_sims),\n",
    "        'min_cosine_similarity': np.min(all_cosine_sims),\n",
    "        'total_parameters_compared': sum(data['total_parameters'] for data in weight_differences.values())\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def print_weight_analysis_summary(analysis):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LLAMA MODEL WEIGHT DIFFERENCE ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Overall statistics\n",
    "    stats = analysis['summary_stats']\n",
    "    print(f\"\\nðŸ“Š OVERALL STATISTICS:\")\n",
    "    print(f\"  â€¢ Total layers compared: {stats['total_layers_compared']}\")\n",
    "    print(f\"  â€¢ Total parameters compared: {stats['total_parameters_compared']:,}\")\n",
    "    print(f\"  â€¢ Mean Frobenius norm: {stats['mean_frobenius_norm']:.2e}\")\n",
    "    print(f\"  â€¢ Mean relative Frobenius norm: {stats['mean_frobenius_norm_relative']:.8f}\")\n",
    "    print(f\"  â€¢ Max Frobenius norm: {stats['max_frobenius_norm']:.2e}\")\n",
    "    print(f\"  â€¢ Min Frobenius norm: {stats['min_frobenius_norm']:.2e}\")\n",
    "    print(f\"  â€¢ Mean cosine similarity: {stats['mean_cosine_similarity']:.8f}\")\n",
    "    print(f\"  â€¢ Min cosine similarity: {stats['min_cosine_similarity']:.8f}\")\n",
    "    print(f\"  â€¢ Mean significant difference ratio: {stats['mean_significant_diff_ratio']:.4f}\")\n",
    "    \n",
    "    # Component type analysis\n",
    "    print(f\"\\nðŸ”§ BY COMPONENT TYPE:\")\n",
    "    for comp_type, comp_data in analysis['by_component_type'].items():\n",
    "        frob_norms = [item['frobenius_norm_relative'] for item in comp_data]\n",
    "        cosine_sims = [item['cosine_similarity'] for item in comp_data]\n",
    "        sig_ratios = [item['significant_diff_ratio'] for item in comp_data]\n",
    "        \n",
    "        print(f\"  {comp_type.upper()}:\")\n",
    "        print(f\"    - Count: {len(comp_data)} layers\")\n",
    "        print(f\"    - Mean relative Frobenius: {np.mean(frob_norms):.8f} Â± {np.std(frob_norms):.8f}\")\n",
    "        print(f\"    - Mean cosine similarity: {np.mean(cosine_sims):.8f} Â± {np.std(cosine_sims):.8f}\")\n",
    "        print(f\"    - Mean sig. diff ratio: {np.mean(sig_ratios):.4f}\")\n",
    "    \n",
    "    # Layer depth analysis (if available)\n",
    "    if analysis['by_layer_depth']:\n",
    "        print(f\"\\nðŸ“ˆ BY LAYER DEPTH:\")\n",
    "        for depth in sorted(analysis['by_layer_depth'].keys())[:10]:  # Show first 10 layers\n",
    "            depth_data = analysis['by_layer_depth'][depth]\n",
    "            frob_norms = [item['frobenius_norm_relative'] for item in depth_data]\n",
    "            cosine_sims = [item['cosine_similarity'] for item in depth_data]\n",
    "            \n",
    "            print(f\"  Layer {depth}: Frob={np.mean(frob_norms):.6f}, Cosine={np.mean(cosine_sims):.6f}\")\n",
    "    \n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec280794",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_1 = get_model_weights(model_1)\n",
    "weights_2 = get_model_weights(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566bf7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing 291 weight matrices...\n",
      "Processing 1/291: layer_22_down_proj\n",
      "Processing 11/291: layer_15_post_attention_layernorm\n",
      "Processing 21/291: layer_27_gate_proj\n",
      "Processing 31/291: layer_31_post_attention_layernorm\n",
      "Processing 41/291: layer_3_q_proj\n",
      "Processing 51/291: layer_17_up_proj\n",
      "Processing 61/291: layer_14_up_proj\n",
      "Processing 71/291: layer_15_gate_proj\n",
      "Processing 81/291: layer_17_post_attention_layernorm\n",
      "Processing 91/291: layer_8_down_proj\n",
      "Processing 101/291: layer_24_input_layernorm\n",
      "Processing 111/291: layer_21_input_layernorm\n",
      "Processing 121/291: layer_28_v_proj\n",
      "Processing 131/291: layer_6_v_proj\n",
      "Processing 141/291: layer_29_v_proj\n",
      "Processing 151/291: layer_20_q_proj\n",
      "Processing 161/291: layer_12_o_proj\n",
      "Processing 171/291: layer_12_gate_proj\n",
      "Processing 181/291: layer_20_up_proj\n",
      "Processing 191/291: layer_19_q_proj\n",
      "Processing 201/291: layer_22_post_attention_layernorm\n",
      "Processing 211/291: final_norm\n",
      "Processing 221/291: layer_14_input_layernorm\n",
      "Processing 231/291: layer_26_k_proj\n",
      "Processing 241/291: layer_8_o_proj\n",
      "Processing 251/291: layer_11_gate_proj\n",
      "Processing 261/291: layer_18_up_proj\n",
      "Processing 271/291: layer_31_input_layernorm\n",
      "Processing 281/291: layer_30_input_layernorm\n",
      "Processing 291/291: layer_25_gate_proj\n"
     ]
    }
   ],
   "source": [
    "weight_differences = calculate_weight_differences(weights_1, weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = analyze_weight_patterns(weight_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8f2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LLAMA MODEL WEIGHT DIFFERENCE ANALYSIS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š OVERALL STATISTICS:\n",
      "  â€¢ Total layers compared: 291\n",
      "  â€¢ Total parameters compared: 6,738,415,616\n",
      "  â€¢ Mean Frobenius norm: 5.00e+00\n",
      "  â€¢ Mean relative Frobenius norm: 0.05240598\n",
      "  â€¢ Max Frobenius norm: 2.33e+01\n",
      "  â€¢ Min Frobenius norm: 6.37e-02\n",
      "  â€¢ Mean cosine similarity: 1.00115807\n",
      "  â€¢ Min cosine similarity: 0.99230218\n",
      "  â€¢ Mean significant difference ratio: 0.9642\n",
      "\n",
      "ðŸ”§ BY COMPONENT TYPE:\n",
      "  MLP:\n",
      "    - Count: 96 layers\n",
      "    - Mean relative Frobenius: 0.06610288 Â± 0.00257659\n",
      "    - Mean cosine similarity: 1.00398319 Â± 0.00041742\n",
      "    - Mean sig. diff ratio: 0.9729\n",
      "  ATTENTION:\n",
      "    - Count: 128 layers\n",
      "    - Mean relative Frobenius: 0.06287519 Â± 0.01413015\n",
      "    - Mean cosine similarity: 0.99922307 Â± 0.00117901\n",
      "    - Mean sig. diff ratio: 0.9713\n",
      "  NORMALIZATION:\n",
      "    - Count: 65 layers\n",
      "    - Mean relative Frobenius: 0.01038052 Â± 0.00265356\n",
      "    - Mean cosine similarity: 0.99998514 Â± 0.00004352\n",
      "    - Mean sig. diff ratio: 0.9371\n",
      "  EMBEDDING:\n",
      "    - Count: 1 layers\n",
      "    - Mean relative Frobenius: 0.05791559 Â± 0.00000000\n",
      "    - Mean cosine similarity: 1.02927232 Â± 0.00000000\n",
      "    - Mean sig. diff ratio: 0.9617\n",
      "  OUTPUT:\n",
      "    - Count: 1 layers\n",
      "    - Mean relative Frobenius: 0.12358926 Â± 0.00000000\n",
      "    - Mean cosine similarity: 1.02575266 Â± 0.00000000\n",
      "    - Mean sig. diff ratio: 0.9832\n",
      "\n",
      "ðŸ“ˆ BY LAYER DEPTH:\n",
      "  Layer 0: Frob=0.061750, Cosine=1.000780\n",
      "  Layer 1: Frob=0.057145, Cosine=1.000603\n",
      "  Layer 2: Frob=0.048795, Cosine=1.001271\n",
      "  Layer 3: Frob=0.051349, Cosine=1.001073\n",
      "  Layer 4: Frob=0.050610, Cosine=1.001082\n",
      "  Layer 5: Frob=0.049889, Cosine=1.001132\n",
      "  Layer 6: Frob=0.052620, Cosine=1.001073\n",
      "  Layer 7: Frob=0.052589, Cosine=1.001031\n",
      "  Layer 8: Frob=0.052245, Cosine=1.001056\n",
      "  Layer 9: Frob=0.051850, Cosine=1.001013\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print_weight_analysis_summary(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3bf55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for activation capture\n",
    "activations_model_1 = {}\n",
    "activations_model_2 = {}\n",
    "current_hooks = []\n",
    "hook_errors = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_activations():\n",
    "    global activations_model_1, activations_model_2\n",
    "    activations_model_1.clear()\n",
    "    activations_model_2.clear()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def remove_all_hooks():\n",
    "    global current_hooks\n",
    "    for hook in current_hooks:\n",
    "        try:\n",
    "            hook.remove()\n",
    "        except:\n",
    "            pass\n",
    "    current_hooks.clear()\n",
    "\n",
    "def get_activation_hook(name, model_name):\n",
    "    def hook(module, input, output):\n",
    "        global hook_errors\n",
    "        try:\n",
    "            # Handle output\n",
    "            if isinstance(output, tuple):\n",
    "                activation = output[0] if len(output) > 0 and output[0] is not None else None\n",
    "            else:\n",
    "                activation = output\n",
    "            \n",
    "            # Handle input\n",
    "            input_tensor = None\n",
    "            if input is not None and isinstance(input, tuple) and len(input) > 0:\n",
    "                input_tensor = input[0] if input[0] is not None else None\n",
    "            \n",
    "            # Store activation data\n",
    "            activation_data = {\n",
    "                'output': activation.detach().cpu() if activation is not None else None,\n",
    "                'input': input_tensor.detach().cpu() if input_tensor is not None else None,\n",
    "                'weight': module.weight.detach().cpu() if hasattr(module, 'weight') and module.weight is not None else None,\n",
    "                'bias': module.bias.detach().cpu() if hasattr(module, 'bias') and module.bias is not None else None\n",
    "            }\n",
    "            \n",
    "            if model_name == \"Model_1\":\n",
    "                activations_model_1[name] = activation_data\n",
    "            else:\n",
    "                activations_model_2[name] = activation_data\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Hook error in {name} ({model_name}): {str(e)}\"\n",
    "            hook_errors.append(error_msg)\n",
    "            print(f\"WARNING: {error_msg}\")\n",
    "            \n",
    "            # Store None data to prevent missing keys\n",
    "            activation_data = {\n",
    "                'output': None,\n",
    "                'input': None, \n",
    "                'weight': None,\n",
    "                'bias': None\n",
    "            }\n",
    "            \n",
    "            if model_name == \"Model_1\":\n",
    "                activations_model_1[name] = activation_data\n",
    "            else:\n",
    "                activations_model_2[name] = activation_data\n",
    "            \n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_llama_hooks(model, model_name, layer_range=None, max_layers=None):\n",
    "    global current_hooks, hook_errors\n",
    "    hooks = []\n",
    "    successful_hooks = 0\n",
    "    failed_hooks = 0\n",
    "    \n",
    "    hook_errors.clear()\n",
    "    \n",
    "    total_layers = len(model.model.layers)\n",
    "    if max_layers is not None:\n",
    "        total_layers = min(total_layers, max_layers)\n",
    "    \n",
    "    if layer_range is None:\n",
    "        layer_range = range(total_layers)\n",
    "    \n",
    "    print(f\"Registering hooks for {model_name}: {len(layer_range)} layers\")\n",
    "    \n",
    "    for i in layer_range:\n",
    "        if i >= len(model.model.layers):\n",
    "            continue\n",
    "            \n",
    "        layer = model.model.layers[i]\n",
    "        layer_prefix = f\"layer_{i}\"\n",
    "        \n",
    "        components_to_hook = [\n",
    "            (layer.self_attn.q_proj, f\"{layer_prefix}_attention_q\"),\n",
    "            (layer.self_attn.k_proj, f\"{layer_prefix}_attention_k\"),\n",
    "            (layer.self_attn.v_proj, f\"{layer_prefix}_attention_v\"),\n",
    "            (layer.self_attn.o_proj, f\"{layer_prefix}_attention_output\"),\n",
    "            (layer.mlp.gate_proj, f\"{layer_prefix}_mlp_gate\"),\n",
    "            (layer.mlp.up_proj, f\"{layer_prefix}_mlp_up\"),\n",
    "            (layer.mlp.down_proj, f\"{layer_prefix}_mlp_down\"),\n",
    "            (layer.input_layernorm, f\"{layer_prefix}_input_norm\"),\n",
    "            (layer.post_attention_layernorm, f\"{layer_prefix}_post_attn_norm\"),\n",
    "        ]\n",
    "        \n",
    "        for module, hook_name in components_to_hook:\n",
    "            try:\n",
    "                hook = module.register_forward_hook(\n",
    "                    get_activation_hook(hook_name, model_name)\n",
    "                )\n",
    "                hooks.append(hook)\n",
    "                successful_hooks += 1\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Failed to register {hook_name}: {str(e)}\"\n",
    "                hook_errors.append(error_msg)\n",
    "                failed_hooks += 1\n",
    "    \n",
    "    # Register final components\n",
    "    try:\n",
    "        hooks.append(model.model.norm.register_forward_hook(\n",
    "            get_activation_hook(\"final_norm\", model_name)\n",
    "        ))\n",
    "        hooks.append(model.lm_head.register_forward_hook(\n",
    "            get_activation_hook(\"lm_head\", model_name)\n",
    "        ))\n",
    "        successful_hooks += 2\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to register final components: {str(e)}\"\n",
    "        hook_errors.append(error_msg)\n",
    "        failed_hooks += 2\n",
    "    \n",
    "    current_hooks.extend(hooks)\n",
    "    \n",
    "    print(f\"Hook registration complete for {model_name}:\")\n",
    "    print(f\"  âœ“ Successful: {successful_hooks}\")\n",
    "    print(f\"  âœ— Failed: {failed_hooks}\")\n",
    "    \n",
    "    return hooks\n",
    "\n",
    "def select_neurons_per_token_position(activations1, activations2, selection_method='min_diff', seed=42):\n",
    "    np.random.seed(seed)\n",
    "    selected_neurons = {}\n",
    "    \n",
    "    print(f\"Selecting neurons per token position from {len(activations1)} layers...\")\n",
    "    print(f\"Selection method: {selection_method}\")\n",
    "    \n",
    "    for layer_name, layer_data in activations1.items():\n",
    "        if not isinstance(layer_data, dict):\n",
    "            continue\n",
    "            \n",
    "        activation1 = layer_data.get('output')\n",
    "        activation2 = activations2.get(layer_name, {}).get('output')\n",
    "\n",
    "        if activation1 is None or activation2 is None:\n",
    "            print(f\"Skipping {layer_name}: Missing activation data\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            if len(activation1.shape) == 3:  # [batch, seq_len, hidden_size]\n",
    "                batch_size, seq_len, hidden_size = activation1.shape\n",
    "                \n",
    "                if hidden_size == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Select neurons for EACH token position separately\n",
    "                token_selections = {}\n",
    "                \n",
    "                for token_pos in range(seq_len):\n",
    "                    # Get activations for this specific token position\n",
    "                    token_act1 = activation1[0, token_pos, :]  # [hidden_size]\n",
    "                    token_act2 = activation2[0, token_pos, :]  # [hidden_size]\n",
    "                    \n",
    "                    # Calculate differences for this token\n",
    "                    diff = torch.abs(token_act1 - token_act2)\n",
    "                    \n",
    "                    # Select neuron based on method\n",
    "                    if selection_method == 'min_diff':\n",
    "                        neuron_idx = torch.argmin(diff).item()\n",
    "                    elif selection_method == 'max_diff':\n",
    "                        neuron_idx = torch.argmax(diff).item()\n",
    "                    elif selection_method == 'random':\n",
    "                        neuron_idx = np.random.randint(0, hidden_size)\n",
    "                    elif selection_method == 'high_activation':\n",
    "                        # Select neuron with highest activation in model 1\n",
    "                        neuron_idx = torch.argmax(torch.abs(token_act1)).item()\n",
    "                    else:\n",
    "                        neuron_idx = torch.argmin(diff).item()  # Default to min_diff\n",
    "                    \n",
    "                    token_selections[token_pos] = {\n",
    "                        'neuron_index': neuron_idx,\n",
    "                        'difference': diff[neuron_idx].item(),\n",
    "                        'activation1_value': token_act1[neuron_idx].item(),\n",
    "                        'activation2_value': token_act2[neuron_idx].item(),\n",
    "                        'abs_activation1': abs(token_act1[neuron_idx].item()),\n",
    "                        'abs_activation2': abs(token_act2[neuron_idx].item()),\n",
    "                        'selection_method': selection_method\n",
    "                    }\n",
    "                \n",
    "                selected_neurons[layer_name] = {\n",
    "                    'per_token_selections': token_selections,\n",
    "                    'sequence_length': seq_len,\n",
    "                    'hidden_size': hidden_size,\n",
    "                    'activation_shape': list(activation1.shape),\n",
    "                    'layer_type': get_component_type(layer_name)\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error selecting neurons for {layer_name}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    print(f\"Successfully selected neurons from {len(selected_neurons)} layers\")\n",
    "    return selected_neurons\n",
    "\n",
    "def get_component_type(layer_name):\n",
    "    if 'attention' in layer_name:\n",
    "        return 'attention'\n",
    "    elif 'mlp' in layer_name:\n",
    "        return 'mlp'\n",
    "    elif 'norm' in layer_name:\n",
    "        return 'normalization'\n",
    "    elif 'lm_head' in layer_name:\n",
    "        return 'output'\n",
    "    elif 'embed' in layer_name:\n",
    "        return 'embedding'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_single_token_neuron(layer_name, neuron_idx, token_pos, \n",
    "                                 layer_1_data, layer_2_data):\n",
    "\n",
    "    input_tensor = layer_1_data.get('input')\n",
    "    if input_tensor is None or token_pos >= input_tensor.shape[1]:\n",
    "        return {'error': 'Missing or invalid input data'}\n",
    "    \n",
    "    # Get input for this specific token\n",
    "    token_input = input_tensor[0, token_pos, :]  # [hidden_size]\n",
    "    \n",
    "    # Get weights\n",
    "    w1 = layer_1_data.get('weight')\n",
    "    w2 = layer_2_data.get('weight')\n",
    "    b1 = layer_1_data.get('bias')\n",
    "    b2 = layer_2_data.get('bias')\n",
    "    \n",
    "    if w1 is None or w2 is None:\n",
    "        return {'error': 'Missing weight data'}\n",
    "    \n",
    "    try:\n",
    "        # Calculate for this specific token and neuron\n",
    "        if 'norm' in layer_name:\n",
    "            # Layer norm calculation: weight * normalized_input + bias\n",
    "            if neuron_idx >= w1.shape[0] or neuron_idx >= token_input.shape[0]:\n",
    "                return {'error': 'Index out of bounds for layer norm'}\n",
    "                \n",
    "            calc_1 = w1[neuron_idx].item() * token_input[neuron_idx].item()\n",
    "            calc_2 = w2[neuron_idx].item() * token_input[neuron_idx].item()\n",
    "            \n",
    "            if b1 is not None and neuron_idx < b1.shape[0]:\n",
    "                calc_1 += b1[neuron_idx].item()\n",
    "            if b2 is not None and neuron_idx < b2.shape[0]:\n",
    "                calc_2 += b2[neuron_idx].item()\n",
    "                \n",
    "        else:\n",
    "            # Linear layer calculation: input @ weight.T + bias\n",
    "            if neuron_idx >= w1.shape[0]:\n",
    "                return {'error': 'Neuron index out of bounds'}\n",
    "                \n",
    "            calc_1 = torch.matmul(token_input, w1[neuron_idx, :]).item()\n",
    "            calc_2 = torch.matmul(token_input, w2[neuron_idx, :]).item()\n",
    "            \n",
    "            if b1 is not None and neuron_idx < b1.shape[0]:\n",
    "                calc_1 += b1[neuron_idx].item()\n",
    "            if b2 is not None and neuron_idx < b2.shape[0]:\n",
    "                calc_2 += b2[neuron_idx].item()\n",
    "            \n",
    "            # Apply activation function for MLP components\n",
    "            if 'mlp_gate' in layer_name or 'mlp_up' in layer_name:\n",
    "                calc_1 = F.silu(torch.tensor(calc_1)).item()\n",
    "                calc_2 = F.silu(torch.tensor(calc_2)).item()\n",
    "        \n",
    "        # Get actual outputs from the models\n",
    "        actual_1 = layer_1_data.get('output')\n",
    "        actual_2 = layer_2_data.get('output')\n",
    "        \n",
    "        actual_1_val = None\n",
    "        actual_2_val = None\n",
    "        \n",
    "        if actual_1 is not None and token_pos < actual_1.shape[1] and neuron_idx < actual_1.shape[2]:\n",
    "            actual_1_val = actual_1[0, token_pos, neuron_idx].item()\n",
    "        if actual_2 is not None and token_pos < actual_2.shape[1] and neuron_idx < actual_2.shape[2]:\n",
    "            actual_2_val = actual_2[0, token_pos, neuron_idx].item()\n",
    "        \n",
    "        # Calculate errors between our calculations and actual outputs\n",
    "        calc_error_1 = abs(calc_1 - actual_1_val) if actual_1_val is not None else None\n",
    "        calc_error_2 = abs(calc_2 - actual_2_val) if actual_2_val is not None else None\n",
    "        \n",
    "        return {\n",
    "            'token_position': token_pos,\n",
    "            'neuron_index': neuron_idx,\n",
    "            'model_1_calculated': calc_1,\n",
    "            'model_2_calculated': calc_2,\n",
    "            'calculation_difference': calc_1 - calc_2,\n",
    "            'model_1_actual': actual_1_val,\n",
    "            'model_2_actual': actual_2_val,\n",
    "            'actual_difference': (actual_1_val - actual_2_val) if (actual_1_val is not None and actual_2_val is not None) else None,\n",
    "            'calculation_error_1': calc_error_1,\n",
    "            'calculation_error_2': calc_error_2,\n",
    "            'layer_type': get_component_type(layer_name)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'error': f'Calculation failed: {str(e)}'}\n",
    "\n",
    "def compare_neuron_calculations_per_token(model_1_activations, model_2_activations, \n",
    "                                        selected_neurons):\n",
    "    comparison_results = {}\n",
    "    \n",
    "    print(f\"Comparing calculations for {len(selected_neurons)} layers...\")\n",
    "    \n",
    "    for layer_name, neuron_info in selected_neurons.items():\n",
    "        if 'per_token_selections' not in neuron_info:\n",
    "            continue\n",
    "            \n",
    "        results = {\n",
    "            'layer_type': neuron_info.get('layer_type', get_component_type(layer_name)),\n",
    "            'sequence_length': neuron_info['sequence_length'],\n",
    "            'hidden_size': neuron_info['hidden_size'],\n",
    "            'token_analyses': {},\n",
    "            'summary_stats': {}\n",
    "        }\n",
    "        \n",
    "        # Get layer data\n",
    "        layer_1_data = model_1_activations.get(layer_name, {})\n",
    "        layer_2_data = model_2_activations.get(layer_name, {})\n",
    "        \n",
    "        if not isinstance(layer_1_data, dict) or not isinstance(layer_2_data, dict):\n",
    "            print(f\"Skipping {layer_name}: Invalid layer data\")\n",
    "            continue\n",
    "        \n",
    "        # Analyze each token position with its selected neuron\n",
    "        valid_analyses = 0\n",
    "        calc_diffs = []\n",
    "        actual_diffs = []\n",
    "        calc_errors_1 = []\n",
    "        calc_errors_2 = []\n",
    "        \n",
    "        for token_pos, token_data in neuron_info['per_token_selections'].items():\n",
    "            neuron_idx = token_data['neuron_index']\n",
    "            \n",
    "            # Calculate for this specific token and neuron\n",
    "            token_analysis = calculate_single_token_neuron(\n",
    "                layer_name, neuron_idx, token_pos,\n",
    "                layer_1_data, layer_2_data\n",
    "            )\n",
    "            \n",
    "            # Add selection info to analysis\n",
    "            if 'error' not in token_analysis:\n",
    "                token_analysis.update({\n",
    "                    'selected_activation1': token_data['activation1_value'],\n",
    "                    'selected_activation2': token_data['activation2_value'],\n",
    "                    'selection_difference': token_data['difference'],\n",
    "                    'selection_method': token_data.get('selection_method', 'unknown')\n",
    "                })\n",
    "                \n",
    "                valid_analyses += 1\n",
    "                calc_diffs.append(token_analysis['calculation_difference'])\n",
    "                \n",
    "                if token_analysis['actual_difference'] is not None:\n",
    "                    actual_diffs.append(token_analysis['actual_difference'])\n",
    "                if token_analysis['calculation_error_1'] is not None:\n",
    "                    calc_errors_1.append(token_analysis['calculation_error_1'])\n",
    "                if token_analysis['calculation_error_2'] is not None:\n",
    "                    calc_errors_2.append(token_analysis['calculation_error_2'])\n",
    "            \n",
    "            results['token_analyses'][token_pos] = token_analysis\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        if valid_analyses > 0:\n",
    "            results['summary_stats'] = {\n",
    "                'valid_analyses': valid_analyses,\n",
    "                'total_tokens': len(neuron_info['per_token_selections']),\n",
    "                'mean_calc_difference': np.mean(calc_diffs) if calc_diffs else None,\n",
    "                'std_calc_difference': np.std(calc_diffs) if calc_diffs else None,\n",
    "                'max_abs_calc_difference': max([abs(d) for d in calc_diffs]) if calc_diffs else None,\n",
    "                'mean_actual_difference': np.mean(actual_diffs) if actual_diffs else None,\n",
    "                'mean_calc_error_1': np.mean(calc_errors_1) if calc_errors_1 else None,\n",
    "                'mean_calc_error_2': np.mean(calc_errors_2) if calc_errors_2 else None,\n",
    "                'unique_neurons_selected': len(set(td['neuron_index'] for td in neuron_info['per_token_selections'].values()))\n",
    "            }\n",
    "        \n",
    "        comparison_results[layer_name] = results\n",
    "    \n",
    "    print(f\"Completed comparisons for {len(comparison_results)} layers\")\n",
    "    return comparison_results\n",
    "\n",
    "def save_detailed_results_per_token(comparison_results, filename=\"per_token_neuron_analysis.csv\"):\n",
    "    rows = []\n",
    "    \n",
    "    input_text = comparison_results.get('input_text', 'Unknown')\n",
    "    \n",
    "    for layer_name, layer_data in comparison_results.get('layer_comparisons', {}).items():\n",
    "        if 'token_analyses' not in layer_data:\n",
    "            continue\n",
    "            \n",
    "        for token_pos, token_analysis in layer_data['token_analyses'].items():\n",
    "            if 'error' in token_analysis:\n",
    "                # Save error rows too\n",
    "                row = {\n",
    "                    'input_text': input_text[:100],\n",
    "                    'layer_name': layer_name,\n",
    "                    'layer_type': layer_data.get('layer_type', 'unknown'),\n",
    "                    'token_position': token_pos,\n",
    "                    'neuron_index': None,\n",
    "                    'error': token_analysis['error'],\n",
    "                    'model_1_calculated': None,\n",
    "                    'model_2_calculated': None,\n",
    "                    'calculation_difference': None,\n",
    "                    'model_1_actual': None,\n",
    "                    'model_2_actual': None,\n",
    "                    'actual_difference': None,\n",
    "                    'calculation_error_1': None,\n",
    "                    'calculation_error_2': None,\n",
    "                    'selected_activation1': None,\n",
    "                    'selected_activation2': None,\n",
    "                    'selection_difference': None,\n",
    "                    'selection_method': None\n",
    "                }\n",
    "            else:\n",
    "                row = {\n",
    "                    'input_text': input_text[:100],\n",
    "                    'layer_name': layer_name,\n",
    "                    'layer_type': token_analysis.get('layer_type', 'unknown'),\n",
    "                    'token_position': token_analysis['token_position'],\n",
    "                    'neuron_index': token_analysis['neuron_index'],\n",
    "                    'error': None,\n",
    "                    'model_1_calculated': token_analysis['model_1_calculated'],\n",
    "                    'model_2_calculated': token_analysis['model_2_calculated'],\n",
    "                    'calculation_difference': token_analysis['calculation_difference'],\n",
    "                    'abs_calculation_difference': abs(token_analysis['calculation_difference']),\n",
    "                    'model_1_actual': token_analysis['model_1_actual'],\n",
    "                    'model_2_actual': token_analysis['model_2_actual'],\n",
    "                    'actual_difference': token_analysis['actual_difference'],\n",
    "                    'abs_actual_difference': abs(token_analysis['actual_difference']) if token_analysis['actual_difference'] is not None else None,\n",
    "                    'calculation_error_1': token_analysis['calculation_error_1'],\n",
    "                    'calculation_error_2': token_analysis['calculation_error_2'],\n",
    "                    'selected_activation1': token_analysis.get('selected_activation1'),\n",
    "                    'selected_activation2': token_analysis.get('selected_activation2'),\n",
    "                    'selection_difference': token_analysis.get('selection_difference'),\n",
    "                    'selection_method': token_analysis.get('selection_method')\n",
    "                }\n",
    "            \n",
    "            rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Save to CSV\n",
    "    if os.path.exists(filename):\n",
    "        df.to_csv(filename, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"Saved {len(rows)} rows to {filename}\")\n",
    "    return df\n",
    "\n",
    "def run_comparison_per_token(text_input, selection_method='min_diff', seed=42, max_layers=None):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {text_input[:50]}...\")\n",
    "    print(f\"Selection method: {selection_method}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Clear previous data and free memory\n",
    "    clear_activations()\n",
    "    remove_all_hooks()\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(\n",
    "        text_input, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "    \n",
    "    print(f\"Input tokens: {inputs['input_ids'].shape[1]}\")\n",
    "    \n",
    "    try:\n",
    "        # Register hooks\n",
    "        print(\"\\n1. Registering hooks...\")\n",
    "        hooks_1 = register_llama_hooks(model_1, \"Model_1\", max_layers=max_layers)\n",
    "        hooks_2 = register_llama_hooks(model_2, \"Model_2\", max_layers=max_layers)\n",
    "        \n",
    "        if len(hooks_1) == 0 or len(hooks_2) == 0:\n",
    "            raise Exception(\"Failed to register hooks\")\n",
    "        \n",
    "        # Run models\n",
    "        print(\"\\n2. Running models...\")\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            outputs_1 = model_1(**inputs)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            outputs_2 = model_2(**inputs)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"\\n3. Activation capture results:\")\n",
    "        print(f\"   Model 1: {len(activations_model_1)} layers captured\")\n",
    "        print(f\"   Model 2: {len(activations_model_2)} layers captured\")\n",
    "        \n",
    "        # Select neurons per token position\n",
    "        print(\"\\n4. Selecting neurons per token position...\")\n",
    "        selected_neurons = select_neurons_per_token_position(\n",
    "            activations_model_1, activations_model_2, \n",
    "            selection_method=selection_method, seed=seed\n",
    "        )\n",
    "        \n",
    "        # Compare activations\n",
    "        print(\"\\n5. Comparing activations...\")\n",
    "        comparison_results = compare_neuron_calculations_per_token(\n",
    "            activations_model_1,\n",
    "            activations_model_2,\n",
    "            selected_neurons\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n6. Results summary:\")\n",
    "        print(f\"   Layers with comparisons: {len(comparison_results)}\")\n",
    "        \n",
    "        # Calculate overall statistics\n",
    "        total_valid = sum(r['summary_stats'].get('valid_analyses', 0) for r in comparison_results.values())\n",
    "        total_tokens = sum(r['summary_stats'].get('total_tokens', 0) for r in comparison_results.values())\n",
    "        \n",
    "        print(f\"   Total valid analyses: {total_valid}\")\n",
    "        print(f\"   Total token positions: {total_tokens}\")\n",
    "        \n",
    "        return {\n",
    "            'input_text': text_input,\n",
    "            'tokenized_input': inputs,\n",
    "            'model_1_output': outputs_1.logits,\n",
    "            'model_2_output': outputs_2.logits,\n",
    "            'layer_comparisons': comparison_results,\n",
    "            'selected_neurons': selected_neurons,\n",
    "            'hook_errors': hook_errors.copy(),\n",
    "            'layers_captured_1': len(activations_model_1),\n",
    "            'layers_captured_2': len(activations_model_2),\n",
    "            'selection_method': selection_method,\n",
    "            'total_valid_analyses': total_valid,\n",
    "            'total_token_positions': total_tokens\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR in run_comparison_per_token: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            'input_text': text_input,\n",
    "            'error': str(e),\n",
    "            'layer_comparisons': {},\n",
    "            'selected_neurons': {},\n",
    "            'hook_errors': hook_errors.copy(),\n",
    "            'layers_captured_1': len(activations_model_1),\n",
    "            'layers_captured_2': len(activations_model_2),\n",
    "            'selection_method': selection_method\n",
    "        }\n",
    "    \n",
    "    finally:\n",
    "        remove_all_hooks()\n",
    "        clear_activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbfda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TEXTS = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming the world of technology.\",\n",
    "    \"In a hole in the ground there lived a hobbit.\",\n",
    "    \"To be or not to be, that is the question Shakespeare posed.\",\n",
    "    \"Machine learning models require large datasets for training.\",\n",
    "    \"The mitochondria is the powerhouse of the cell in biology.\",\n",
    "    \"Climate change is causing unprecedented shifts in global weather patterns.\",\n",
    "    \"Mozart composed his first symphony at the age of eight years old.\",\n",
    "    \"The stock market experienced significant volatility during the pandemic crisis.\",\n",
    "    \"Quantum physics reveals the strange behavior of particles at subatomic levels.\",\n",
    "    \"Professional chefs recommend using fresh herbs to enhance flavor profiles.\",\n",
    "    \"Ancient Egyptian pyramids were built using sophisticated engineering techniques.\",\n",
    "    \"Regular exercise and proper nutrition are essential for maintaining good health.\",\n",
    "    \"The International Space Station orbits Earth approximately every ninety minutes.\",\n",
    "    \"Cryptocurrency markets operate twenty-four hours a day across global exchanges.\",\n",
    "    \"Vincent van Gogh painted Starry Night while staying at an asylum.\",\n",
    "    \"Professional athletes must maintain strict training regimens throughout their careers.\",\n",
    "    \"The Amazon rainforest produces twenty percent of the world's oxygen supply.\",\n",
    "    \"Modern architecture emphasizes clean lines and functional design principles.\",\n",
    "    \"Forensic scientists use DNA analysis to solve complex criminal investigations.\",\n",
    "    \"Traditional Japanese tea ceremonies follow centuries-old ritualistic practices.\",\n",
    "    \"Marine biologists study coral reef ecosystems threatened by ocean acidification.\",\n",
    "    \"The Renaissance period marked a cultural rebirth in European art and science.\",\n",
    "    \"Cybersecurity experts work tirelessly to protect digital infrastructure from threats.\",\n",
    "    \"Sustainable agriculture practices help preserve soil quality for future generations.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31afe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing text 1/5 ===\n",
      "Processing: The quick brown fox jumps over the lazy dog....\n",
      "Input tokens: 13\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "Visualization saved to neuron_comparison_text_0.png\n",
      "Completed text 1\n",
      "\n",
      "=== Processing text 2/5 ===\n",
      "Processing: Artificial intelligence is transforming the world ...\n",
      "Input tokens: 13\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "Visualization saved to neuron_comparison_text_1.png\n",
      "Completed text 2\n",
      "\n",
      "=== Processing text 3/5 ===\n",
      "Processing: In a hole in the ground there lived a hobbit....\n",
      "Input tokens: 14\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "Visualization saved to neuron_comparison_text_2.png\n",
      "Completed text 3\n",
      "\n",
      "=== Processing text 4/5 ===\n",
      "Processing: To be or not to be, that is the question Shakespea...\n",
      "Input tokens: 16\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "Visualization saved to neuron_comparison_text_3.png\n",
      "Completed text 4\n",
      "\n",
      "=== Processing text 5/5 ===\n",
      "Processing: Machine learning models require large datasets for...\n",
      "Input tokens: 10\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "Visualization saved to neuron_comparison_text_4.png\n",
      "Completed text 5\n"
     ]
    }
   ],
   "source": [
    "# Run with your preferred method\n",
    "PREFERRED_METHOD = 'min_diff'  # Change this to your preferred method\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Running full analysis with method: {PREFERRED_METHOD}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for i, text in enumerate(TEST_TEXTS):\n",
    "    print(f\"\\n=== Processing text {i+1}/{len(TEST_TEXTS)} ===\")\n",
    "    \n",
    "    try:\n",
    "        result = run_comparison_per_token(\n",
    "            text, \n",
    "            selection_method=PREFERRED_METHOD,\n",
    "            seed=42+i,\n",
    "            max_layers=None  # Use all layers\n",
    "        )\n",
    "        \n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Save detailed results\n",
    "        save_detailed_results_per_token(\n",
    "            result, \n",
    "            filename=f\"all_texts_per_token_{PREFERRED_METHOD}.csv\"\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ“ Completed text {i+1}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error processing text {i+1}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
